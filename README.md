# RoboCup 3D 识别挑战赛 - DUT-WZQXJ 团队方案

本项目针对 RoboCup **机器人先进视觉赛项-3D识别挑战赛**，设计并实现了一套基于 **YOLOv8** 的双阶段多模型协同检测与融合系统，以实现对复杂场景下目标物的精确、鲁棒识别。

该版本的代码还有一些冗余，以及只支持om推理，可运行在windows平台的代码coming soon。

## 1\. 比赛背景与挑战

本挑战赛旨在评估机器视觉系统在模拟真实环境中的目标识别与分类能力，涉及多轮次、不同目标台布局、多变姿态和复杂光照等干扰条件。我们的解决方案专注于通过模型互补与结果精细融合，克服单一模型在尺度变化、密集目标和边缘检测上的固有局限。

## 2\. 核心技术方案：双阶段多模型协同检测

我们采用\*\*“全局感知 + 局部精检”\*\*的双模型策略，确保系统在高召回率和高精度的平衡。

### 2.1 双模型架构

系统并行运行两个独立的 YOLOv8 模型，利用它们各自的优势：

| 模型 | 角色 | 模型文件 | 核心作用 |
| :--- | :--- | :--- | :--- |
| **整体检测器** | **全局模型** | `model/v8_v1_overall.om` | 对**全幅图像**进行快速检测，擅长定位大尺寸目标。 |
| **局部检测器** | **局部模型** | `model/v8_v2_local.om` | 接收整体模型裁剪出的**桌面扩展区域**，进行高分辨率精细检测，擅长识别密集、小型目标。 |

### 2.2 性能提升机制 (Multi-Model Advantage)

采用双模型策略的核心优势在于：

  * **尺度鲁棒性：** 两个模型可分别在不同图像尺度上进行针对性训练，有效解决同一场景中物体大小差异悬殊的问题。
  * **信息互补：** 局部模型通过放大桌面区域，提高了对小目标和密集目标的**召回率**。整体模型则提供全局视野，**补充**局部裁剪可能遗漏的边缘目标。
  * **精度调优：** 允许对每个模型、每个类别设置**专属的后处理阈值**，实现精细化控制，最大化性能。

## 3\. 超参数与配置管理

所有关键运行与推理参数集中在 `config.py` 文件中，便于系统调优。

| 配置类型 | 参数名 | 关键数值 | 描述与用途 |
| :--- | :--- | :--- | :--- |
| **通用后处理** | `PRED_IOU_THRES` | $0.66$ | \*\*非极大值抑制（NMS）\*\*的 IoU 阈值。 |
| | `PRED_CONF_THRES` | $0.68$ | 全局默认置信度（Confidence）过滤阈值。 |
| **精细化阈值** | `M1/M2_CLASS_SCORE_THRESHOLDS` | (定制化) | **按模型、按类别**定制的置信度阈值。是抑制误报、提升特定类别召回的关键。 |
| **模型输入** | `DESK_EXPANSION_RATIO` | $0.20$ | 整体模型定位 `desk` 后，**向外扩展 20%** 边界，作为局部模型的输入区域，确保边缘目标不丢失。 |
| **输出限制** | `CLASS_MAX_COUNTS` | (定制化) | 根据比赛规则，**限制每个类别最终输出的最大数量**，避免因重复或错误计数导致的扣分。 |
| **通信设置** | `JUDGE_BOX_IP` / `PORT` | 裁判盒地址 | 用于通过 `JudgeBoxClient` 发送最终检测结果。 |

### 3.1 核心融合策略

双模型的结果通过一个定制的**结果融合模块**进行集成，以产生最终的检测列表：

  * **跨模型匹配 ($\text{IoU}_{Match}$)**: 使用 `CROSS_MODEL_MATCH_IOU` ($0.30$) 阈值来判断两个模型的检测框是否指向**同一物体**。
  * **类别冲突仲裁**: 对于匹配上的冲突框，`MERGE_CLASS_PREFERENCE` 字典定义了是采纳全局模型 (`'overall'`) 还是局部模型 (`'local'`) 的类别标签。
  * **额外检测补充**: `SUPPLEMENT_ALLOWED_SOURCES` 定义了未匹配上的检测框（即**补框**）是否允许被加入最终结果，以进一步提升系统的召回性能。

## 4\. 系统运行与流程

系统主程序为 `main.py`，支持灵活的调试和比赛流程控制。

```bash
python main.py
```